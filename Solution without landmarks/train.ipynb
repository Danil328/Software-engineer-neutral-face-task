{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "from skimage.transform import resize\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/danil/Data/Datasets/CelebA/Img'\n",
    "path_to_img = '/media/danil/Data/Datasets/CelebA/Img/img_align_celeba'\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv(os.path.join(path,'list_attr_celeba.txt'), delimiter=\" \")\n",
    "training.Smiling = training.Smiling.map({1:1, -1:0})\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_mouth_df = pd.read_csv(os.path.join(path,'CelebA.csv'))\n",
    "open_mouth_df.columns = ['ImageName', 'open_mouth']\n",
    "open_mouth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.merge(training, open_mouth_df, how='right', on='ImageName')\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "X_train_cv = skf.split(training.values, training['Smiling'].values)\n",
    "\n",
    "index_train_dict = {}\n",
    "index_test_dict = {}\n",
    "for i in range(5):\n",
    "    ind = next(X_train_cv)\n",
    "    index_train_dict['split_{}'.format(i)] = ind[0]\n",
    "    index_test_dict['split_{}'.format(i)] = ind[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier('/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "def cascadeHaar(img):\n",
    "    img = np.array(img, dtype=np.uint8)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    for face in faces:\n",
    "        img = img[max(0,face[1]):max(0,face[1])+max(0,face[3]), max(0,face[0]):max(0,face[0])+max(0,face[2])]\n",
    "        return img, 1\n",
    "    return img, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "hog_face_detector = dlib.get_frontal_face_detector()\n",
    "def hog_face_detection(img):\n",
    "    faces_hog = hog_face_detector(img, 1)\n",
    "    for face in faces_hog:\n",
    "        img = img[max(0,face.top()):max(0,face.bottom()), max(0,face.left()):max(0,face.right())]\n",
    "        return img, 1\n",
    "    return img, 0\n",
    "\n",
    "cnn_face_detector = dlib.cnn_face_detection_model_v1('mmod_human_face_detector.dat')\n",
    "def cnn_face_detection(img):\n",
    "    faces_cnn = cnn_face_detector(img, 1)\n",
    "    for face in faces_cnn:\n",
    "        img = img[max(0,face.rect.top()):max(0,face.rect.bottom()), max(0,face.rect.left()):max(0,face.rect.right())]\n",
    "        return img, 1\n",
    "    return img, 0\n",
    "\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "def mtcnn_detect(img):\n",
    "    faces = detector.detect_faces(img)\n",
    "    for face in faces:\n",
    "        img = img[max(0,face['box'][1]):max(0,face['box'][1]) + max(0,face['box'][3]), \n",
    "                  max(0,face['box'][0]): max(0,face['box'][0]) + max(0,face['box'][2])]\n",
    "        return img, 1\n",
    "    return img, 0\n",
    "\n",
    "def get_face(img):\n",
    "    img, label = mtcnn_detect(img)\n",
    "    if label==0:\n",
    "        img, label = hog_face_detection(img)\n",
    "        if label==0:\n",
    "            img, label = cnn_face_detection(img)\n",
    "            if label==0:\n",
    "                img, label = cascadeHaar(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = shuffle(training)\n",
    "out_rgb = []\n",
    "out_smiles = []\n",
    "out_mouths = []\n",
    "for path_img, smile, open_mouth in tqdm_notebook(training[['ImageName', 'Smiling', 'open_mouth']].values):\n",
    "    img = cv.imread(os.path.join(path_to_img, path_img))\n",
    "    img, label = get_face(img)\n",
    "    img = resize(img, (224,224,3))\n",
    "    out_rgb += [img]\n",
    "    out_smiles += [smile]\n",
    "    out_mouths += [open_mouth]\n",
    "    if label == 0:\n",
    "        out_rgb.pop()\n",
    "        out_smiles.pop()\n",
    "        out_mouths.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_smiles += out_smiles\n",
    "out_mouths += out_mouths\n",
    "x_train = np.append(out_rgb, [np.fliplr(x) for x in out_rgb], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import NASNetMobile\n",
    "model = NASNetMobile(weights = \"imagenet\", include_top=False, input_shape = (224, 224, 3))\n",
    "\n",
    "from keras.layers import Flatten, Dense, Dropout, BatchNormalization, GlobalMaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = BatchNormalization()(x)\n",
    "x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "x1 = Dense(1024, activation=\"elu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(256, activation=\"elu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "#x1 = Dropout(0.5)(x1)\n",
    "\n",
    "x2 = Dense(1024, activation=\"elu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = Dropout(0.5)(x2)\n",
    "x2 = Dense(256, activation=\"elu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "#x2 = Dropout(0.5)(x2)\n",
    "\n",
    "out_smile = Dense(1, activation=\"sigmoid\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001), name='out_smile')(x1)\n",
    "out_mouth = Dense(1, activation=\"sigmoid\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001), name='out_mouth')(x2)\n",
    "\n",
    "from keras.models import Model\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = [out_smile, out_mouth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "  \n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = {'out_smile':\"binary_crossentropy\", 'out_mouth':\"binary_crossentropy\"}, optimizer = Adam(lr=0.001, decay=0.0001), metrics=[f1], loss_weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "weight_path='solution1.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_out_smile_f1', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only=True)\n",
    "\n",
    "\n",
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    k = 0.1\n",
    "    lrate = initial_lrate * np.exp(-k*epoch)\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(exp_decay)\n",
    "\n",
    "callbacks_list = [lrate, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.fit(x_train, \n",
    "                [out_smiles, out_mouths],\n",
    "                epochs = 30,\n",
    "                batch_size = 64, \n",
    "                validation_split=0.15,\n",
    "                callbacks = callbacks_list,\n",
    "                initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.save_weights(weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = '/media/danil/Data/Datasets/example_data'\n",
    "test_images = os.listdir(os.path.join(path_test,'images'))\n",
    "test_images = [i for i in test_images if 'jpg' in i]\n",
    "\n",
    "test_smile = os.listdir(os.path.join(path_test,'smile'))\n",
    "test_smile = [i for i in test_smile if 'jpg' in i]\n",
    "\n",
    "test_open_mouth = os.listdir(os.path.join(path_test,'open_mouth'))\n",
    "test_open_mouth = [i for i in test_open_mouth if 'jpg' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mouth = []\n",
    "for i in test_images:\n",
    "    if i in test_open_mouth:\n",
    "        test_mouth += [1]\n",
    "    else:\n",
    "        test_mouth += [0]\n",
    "sum(test_mouth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_smiles = []\n",
    "for i in test_images:\n",
    "    if i in test_smile:\n",
    "        test_smiles += [1]\n",
    "    else:\n",
    "        test_smiles += [0]\n",
    "sum(test_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df['image'] = test_images\n",
    "test_df['smile'] = test_smiles\n",
    "test_df['mouth'] = test_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del out_rgb, x_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = [cv.imread(os.path.join(path_test, 'images', i)) for i in test_images]\n",
    "test_imgs = [resize(get_face(i)[0], (224,224,3)) for i in tqdm_notebook(test_imgs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model_final.predict(np.stack(test_imgs, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_smile = roc_auc_score(test_df.smile.values, predict[0])\n",
    "score_mouth = roc_auc_score(test_df.mouth.values, predict[1])\n",
    "\n",
    "f1_score_smile = f1_score(test_df.smile.values, np.round(predict[0]))\n",
    "f1_score_mouth = f1_score(test_df.mouth.values, np.round(predict[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score_smile)\n",
    "print(f1_score_mouth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_smile)\n",
    "print(score_mouth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tresh = np.arange(0.1, 0.9, 0.05)\n",
    "scores_smile = []\n",
    "scores_mouth = []\n",
    "for i in tresh:\n",
    "    scores_smile += [f1_score(test_df.smile.values, np.array(predict[0]>i, dtype=int))]\n",
    "    scores_mouth += [f1_score(test_df.mouth.values, np.array(predict[1]>i, dtype=int))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tresh, scores_smile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
