{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "from skimage.transform import resize\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/danil/Data/Datasets/CelebA/Img'\n",
    "path_to_img = '/media/danil/Data/Datasets/CelebA/Img/img_align_celeba'\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>5_o_Clock_Shadow</th>\n",
       "      <th>Arched_Eyebrows</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bags_Under_Eyes</th>\n",
       "      <th>Bald</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Big_Lips</th>\n",
       "      <th>Big_Nose</th>\n",
       "      <th>Black_Hair</th>\n",
       "      <th>...</th>\n",
       "      <th>Sideburns</th>\n",
       "      <th>Smiling</th>\n",
       "      <th>Straight_Hair</th>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <th>Wearing_Earrings</th>\n",
       "      <th>Wearing_Hat</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ImageName  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  Bags_Under_Eyes  \\\n",
       "0  000001.jpg                -1                1           1               -1   \n",
       "1  000002.jpg                -1               -1          -1                1   \n",
       "2  000003.jpg                -1               -1          -1               -1   \n",
       "3  000004.jpg                -1               -1           1               -1   \n",
       "4  000005.jpg                -1                1           1               -1   \n",
       "\n",
       "   Bald  Bangs  Big_Lips  Big_Nose  Black_Hair  ...    Sideburns  Smiling  \\\n",
       "0    -1     -1        -1        -1          -1  ...           -1        1   \n",
       "1    -1     -1        -1         1          -1  ...           -1        1   \n",
       "2    -1     -1         1        -1          -1  ...           -1        0   \n",
       "3    -1     -1        -1        -1          -1  ...           -1        0   \n",
       "4    -1     -1         1        -1          -1  ...           -1        0   \n",
       "\n",
       "   Straight_Hair  Wavy_Hair  Wearing_Earrings  Wearing_Hat  Wearing_Lipstick  \\\n",
       "0              1         -1                 1           -1                 1   \n",
       "1             -1         -1                -1           -1                -1   \n",
       "2             -1          1                -1           -1                -1   \n",
       "3              1         -1                 1           -1                 1   \n",
       "4             -1         -1                -1           -1                 1   \n",
       "\n",
       "   Wearing_Necklace  Wearing_Necktie  Young  \n",
       "0                -1               -1      1  \n",
       "1                -1               -1      1  \n",
       "2                -1               -1      1  \n",
       "3                 1               -1      1  \n",
       "4                -1               -1      1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = pd.read_csv(os.path.join(path,'list_attr_celeba.txt'), delimiter=\" \")\n",
    "training.Smiling = training.Smiling.map({1:1, -1:0})\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>open_mouth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>055997.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131827.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>052069.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110305.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>098890.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ImageName  open_mouth\n",
       "0  055997.jpg           1\n",
       "1  131827.jpg           1\n",
       "2  052069.jpg           1\n",
       "3  110305.jpg           1\n",
       "4  098890.jpg           1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_mouth_df = pd.read_csv(os.path.join(path,'CelebA.csv'))\n",
    "open_mouth_df.columns = ['ImageName', 'open_mouth']\n",
    "open_mouth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>5_o_Clock_Shadow</th>\n",
       "      <th>Arched_Eyebrows</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bags_Under_Eyes</th>\n",
       "      <th>Bald</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Big_Lips</th>\n",
       "      <th>Big_Nose</th>\n",
       "      <th>Black_Hair</th>\n",
       "      <th>...</th>\n",
       "      <th>Smiling</th>\n",
       "      <th>Straight_Hair</th>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <th>Wearing_Earrings</th>\n",
       "      <th>Wearing_Hat</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "      <th>open_mouth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000077.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000090.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000102.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000115.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000149.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ImageName  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  Bags_Under_Eyes  \\\n",
       "0  000077.jpg                -1               -1           1               -1   \n",
       "1  000090.jpg                -1               -1          -1               -1   \n",
       "2  000102.jpg                -1               -1          -1               -1   \n",
       "3  000115.jpg                -1               -1          -1               -1   \n",
       "4  000149.jpg                -1               -1          -1               -1   \n",
       "\n",
       "   Bald  Bangs  Big_Lips  Big_Nose  Black_Hair     ...      Smiling  \\\n",
       "0    -1      1        -1        -1          -1     ...            1   \n",
       "1    -1     -1        -1        -1          -1     ...            0   \n",
       "2    -1     -1        -1        -1           1     ...            0   \n",
       "3     1     -1        -1        -1          -1     ...            0   \n",
       "4    -1     -1        -1        -1          -1     ...            1   \n",
       "\n",
       "   Straight_Hair  Wavy_Hair  Wearing_Earrings  Wearing_Hat  Wearing_Lipstick  \\\n",
       "0             -1          1                -1           -1                 1   \n",
       "1              1         -1                -1           -1                -1   \n",
       "2             -1         -1                -1           -1                -1   \n",
       "3             -1         -1                -1           -1                -1   \n",
       "4             -1         -1                -1            1                -1   \n",
       "\n",
       "   Wearing_Necklace  Wearing_Necktie  Young  open_mouth  \n",
       "0                -1               -1      1           0  \n",
       "1                -1               -1      1           0  \n",
       "2                -1               -1      1           0  \n",
       "3                -1               -1     -1           0  \n",
       "4                -1               -1      1           1  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = pd.merge(training, open_mouth_df, how='right', on='ImageName')\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3724, 42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "X_train_cv = skf.split(training.values, training['Smiling'].values)\n",
    "\n",
    "index_train_dict = {}\n",
    "index_test_dict = {}\n",
    "for i in range(5):\n",
    "    ind = next(X_train_cv)\n",
    "    index_train_dict['split_{}'.format(i)] = ind[0]\n",
    "    index_test_dict['split_{}'.format(i)] = ind[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier('/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "def cascadeHaar(img):\n",
    "    img = np.array(img, dtype=np.uint8)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    for face in faces:\n",
    "        img = img[max(0,face[1]):max(0,face[1])+max(0,face[3]), max(0,face[0]):max(0,face[0])+max(0,face[2])]\n",
    "        return img, 1\n",
    "    return img, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/mtcnn/layer_factory.py:211: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/mtcnn/layer_factory.py:213: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "hog_face_detector = dlib.get_frontal_face_detector()\n",
    "def hog_face_detection(img):\n",
    "    faces_hog = hog_face_detector(img, 1)\n",
    "    for face in faces_hog:\n",
    "        img = img[max(0,face.top()):max(0,face.bottom()), max(0,face.left()):max(0,face.right())]\n",
    "        return img, 1\n",
    "    return img, 0\n",
    "\n",
    "cnn_face_detector = dlib.cnn_face_detection_model_v1('mmod_human_face_detector.dat')\n",
    "def cnn_face_detection(img):\n",
    "    faces_cnn = cnn_face_detector(img, 1)\n",
    "    for face in faces_cnn:\n",
    "        img = img[max(0,face.rect.top()):max(0,face.rect.bottom()), max(0,face.rect.left()):max(0,face.rect.right())]\n",
    "        return img, 1\n",
    "    return img, 0\n",
    "\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "def mtcnn_detect(img):\n",
    "    faces = detector.detect_faces(img)\n",
    "    for face in faces:\n",
    "        img = img[max(0,face['box'][1]):max(0,face['box'][1]) + max(0,face['box'][3]), \n",
    "                  max(0,face['box'][0]): max(0,face['box'][0]) + max(0,face['box'][2])]\n",
    "        return img, 1\n",
    "    return img, 0\n",
    "\n",
    "def get_face(img):\n",
    "    img, label = mtcnn_detect(img)\n",
    "    if label==0:\n",
    "        img, label = hog_face_detection(img)\n",
    "        if label==0:\n",
    "            img, label = cnn_face_detection(img)\n",
    "            if label==0:\n",
    "                img, label = cascadeHaar(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76720d3327f3484fa82201a828493458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3724), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training = shuffle(training)\n",
    "out_rgb = []\n",
    "out_smiles = []\n",
    "out_mouths = []\n",
    "for path_img, smile, open_mouth in tqdm_notebook(training[['ImageName', 'Smiling', 'open_mouth']].values):\n",
    "    img = cv.imread(os.path.join(path_to_img, path_img))\n",
    "    img, label = get_face(img)\n",
    "    img = resize(img, (224,224,3))\n",
    "    out_rgb += [img]\n",
    "    out_smiles += [smile]\n",
    "    out_mouths += [open_mouth]\n",
    "    if label == 0:\n",
    "        out_rgb.pop()\n",
    "        out_smiles.pop()\n",
    "        out_mouths.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_smiles += out_smiles\n",
    "out_mouths += out_mouths\n",
    "x_train = np.append(out_rgb, [np.fliplr(x) for x in out_rgb], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import NASNetMobile\n",
    "model = NASNetMobile(weights = \"imagenet\", include_top=False, input_shape = (224, 224, 3))\n",
    "\n",
    "from keras.layers import Flatten, Dense, Dropout, BatchNormalization, GlobalMaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = BatchNormalization()(x)\n",
    "x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "x1 = Dense(1024, activation=\"elu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(256, activation=\"elu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "#x1 = Dropout(0.5)(x1)\n",
    "\n",
    "x2 = Dense(1024, activation=\"elu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = Dropout(0.5)(x2)\n",
    "x2 = Dense(256, activation=\"elu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "#x2 = Dropout(0.5)(x2)\n",
    "\n",
    "out_smile = Dense(1, activation=\"sigmoid\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001), name='out_smile')(x1)\n",
    "out_mouth = Dense(1, activation=\"sigmoid\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001), name='out_mouth')(x2)\n",
    "\n",
    "from keras.models import Model\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = [out_smile, out_mouth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "  \n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = {'out_smile':\"binary_crossentropy\", 'out_mouth':\"binary_crossentropy\"}, optimizer = Adam(lr=0.001, decay=0.0001), metrics=[f1], loss_weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "weight_path='solution1.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_out_smile_f1', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only=True)\n",
    "\n",
    "\n",
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    k = 0.1\n",
    "    lrate = initial_lrate * np.exp(-k*epoch)\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(exp_decay)\n",
    "\n",
    "callbacks_list = [lrate, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6300 samples, validate on 1112 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,528,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: normal_A_block_5/normal_concat_5/concat = ConcatV2[N=6, T=DT_FLOAT, Tidx=DT_INT32, _class=[\"loc:@train.../cond_grad\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](normal_A_block_5/adjust_block/adjust_reduction_block_5/adjust_bn_5/cond/Merge, normal_A_block_5/block_1/normal_add_1_5/add, normal_A_block_5/block_2/normal_add_2_5/add, normal_A_block_5/block_3/normal_add_3_5/add, normal_A_block_5/block_4/normal_add_4_5/ArithmeticOptimizer/SimplifyAggregation_Mul_add, normal_A_block_5/block_5/normal_add_5_5/add, training/Adam/gradients/loss/out_smile_loss/Mean_3_grad/Maximum)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics/f1_1/Mean/_13483 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_72998_metrics/f1_1/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1e2366d8a1d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 initial_epoch = 0)\n\u001b[0m",
      "\u001b[0;32m/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/danil/Data/Kaggle/airbus-ship-detection/venv/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,528,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: normal_A_block_5/normal_concat_5/concat = ConcatV2[N=6, T=DT_FLOAT, Tidx=DT_INT32, _class=[\"loc:@train.../cond_grad\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](normal_A_block_5/adjust_block/adjust_reduction_block_5/adjust_bn_5/cond/Merge, normal_A_block_5/block_1/normal_add_1_5/add, normal_A_block_5/block_2/normal_add_2_5/add, normal_A_block_5/block_3/normal_add_3_5/add, normal_A_block_5/block_4/normal_add_4_5/ArithmeticOptimizer/SimplifyAggregation_Mul_add, normal_A_block_5/block_5/normal_add_5_5/add, training/Adam/gradients/loss/out_smile_loss/Mean_3_grad/Maximum)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics/f1_1/Mean/_13483 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_72998_metrics/f1_1/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "model_final.fit(x_train, \n",
    "                [out_smiles, out_mouths],\n",
    "                epochs = 30,\n",
    "                batch_size = 64, \n",
    "                validation_split=0.15,\n",
    "                callbacks = callbacks_list,\n",
    "                initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = '/media/danil/Data/Datasets/example_data'\n",
    "test_images = os.listdir(os.path.join(path_test,'images'))\n",
    "test_images = [i for i in test_images if 'jpg' in i]\n",
    "\n",
    "test_smile = os.listdir(os.path.join(path_test,'smile'))\n",
    "test_smile = [i for i in test_smile if 'jpg' in i]\n",
    "\n",
    "test_open_mouth = os.listdir(os.path.join(path_test,'open_mouth'))\n",
    "test_open_mouth = [i for i in test_open_mouth if 'jpg' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mouth = []\n",
    "for i in test_images:\n",
    "    if i in test_open_mouth:\n",
    "        test_mouth += [1]\n",
    "    else:\n",
    "        test_mouth += [0]\n",
    "sum(test_mouth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_smiles = []\n",
    "for i in test_images:\n",
    "    if i in test_smile:\n",
    "        test_smiles += [1]\n",
    "    else:\n",
    "        test_smiles += [0]\n",
    "sum(test_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df['image'] = test_images\n",
    "test_df['smile'] = test_smiles\n",
    "test_df['mouth'] = test_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del out_rgb, x_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = [cv.imread(os.path.join(path_test, 'images', i)) for i in test_images]\n",
    "test_imgs = [resize(get_face(i)[0], (224,224,3)) for i in tqdm_notebook(test_imgs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model_final.predict(np.stack(test_imgs, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_smile = roc_auc_score(test_df.smile.values, predict[0])\n",
    "score_mouth = roc_auc_score(test_df.mouth.values, predict[1])\n",
    "\n",
    "f1_score_smile = f1_score(test_df.smile.values, np.round(predict[0]))\n",
    "f1_score_mouth = f1_score(test_df.mouth.values, np.round(predict[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score_smile)\n",
    "print(f1_score_mouth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_smile)\n",
    "print(score_mouth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tresh = np.arange(0.1, 0.9, 0.05)\n",
    "scores_smile = []\n",
    "scores_mouth = []\n",
    "for i in tresh:\n",
    "    scores_smile += [f1_score(test_df.smile.values, np.array(predict[0]>i, dtype=int))]\n",
    "    scores_mouth += [f1_score(test_df.mouth.values, np.array(predict[1]>i, dtype=int))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tresh, scores_smile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
